defaults:
  - _self_

wandb:
  entity: "tylerlum"
  project: "NeRF_Grasp_Metric_V1"
  name: ${datetime_str:}
  group: ""
  job_type: ""

data:
  frac_val: 0.1
  frac_test: 0.1
  frac_train: ${eval:1 - ${data.frac_val} - ${data.frac_test}}
  # input_dataset_root_dir: "/scr1/tylerlum"
  input_dataset_root_dir: "/juno/u/tylerlum/github_repos/nerf_grasping/nerf_acronym_grasp_success_datasets"
  input_dataset_path: "nerf_acronym_grasp_success_dataset_608_categories.h5"
  max_num_data_points: ${eval:None}

dataloader:
  batch_size: 16
  num_workers: 8
  pin_memory: True
  load_nerf_grid_inputs_in_ram: False
  load_grasp_successes_in_ram: False
  downsample_factor_x: 5
  downsample_factor_y: 2
  downsample_factor_z: 2

preprocess:
  flip_left_right_randomly: True
  density_type: "ALPHA"
  add_invariance_transformations: False
  rotate_polar_angle: True
  reflect_around_xz_plane_randomly: True
  reflect_around_xy_plane_randomly: True
  remove_y_axis: True

training:
  grad_clip_val: 1.0
  lr: 1e-4
  weight_decay: 1e-3
  betas: (0.9, 0.999)
  label_smoothing: 0.0
  lr_scheduler_name: "constant"
  lr_scheduler_num_warmup_steps: 0
  n_epochs: 20
  log_grad_freq: 5
  log_grad_on_epoch_0: False
  val_freq: 5
  val_on_epoch_0: True
  save_checkpoint_freq: 5
  save_checkpoint_on_epoch_0: False
  confusion_matrix_freq: 5
  save_confusion_matrix_on_epoch_0: False
  use_dataloader_subset: True

classifier:
  conv_encoder_2d_config:
    use_resnet: True
    use_pretrained: True
    pooling_method: "AVG_POOL_CHANNEL"
    film_hidden_layers: [64, 64]

  use_conditioning_2d: True
  conv_encoder_2d_embed_dim: 32
  conv_encoder_2d_mlp_hidden_layers: [64, 64]

  # Conv
  conv_encoder_1d_config:
    use_resnet: True
    pooling_method: "AVG_POOL_CHANNEL"
    film_hidden_layers: [64, 64]
    base_filters: 64
    kernel_size: 16
    stride: 2
    groups: 32
    n_block: 8
    downsample_gap: 6
    increasefilter_gap: 12
    use_do: False

  # Transformer
  transformer_encoder_1d_config:
    pooling_method: "AVG_POOL_CHANNEL"
    n_heads: 8
    n_emb: ${eval:${classifier.transformer_encoder_1d_config.n_heads} * 16} # Need to be divisible by n_heads
    p_drop_emb: 0.1
    p_drop_attn: 0.1
    n_layers: 4

  encoder_1d_type: "TRANSFORMER"

  use_conditioning_1d: True
  head_mlp_hidden_layers: [64, 64]

checkpoint_workspace:
  root_dir: "Train_NeRF_Grasp_Metric_workspaces"
  leaf_dir: ${wandb.name}
  force_no_resume: True

random_seed: 42
visualize_data: False
dry_run: False
