{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a59aada-fcf6-41d9-849d-31d71845789e",
   "metadata": {},
   "source": [
    "# Create NeRF ACRONYM Dataset\n",
    "\n",
    "## Summary (April 23, 2023)\n",
    "\n",
    "The purpose of this script is to create a dataset for predicting the quality of grasps from NeRF representations of objects.\n",
    "\n",
    "## Script Inputs\n",
    "\n",
    "## Dataset\n",
    "```\n",
    "{output_hdf5_filename} with hierarchical structure\n",
    "/\n",
    "├── /nerf_grid_input [shape (N, 4, 80, 20, 30)]\n",
    "├── /grasp_success [shape (N,)]\n",
    "```\n",
    "\n",
    "where the first channel of `nerf_grid_input` is the NeRF density at this point\n",
    "and the remaining channels of `nerf_grid_input` are the x, y, and z coordinates of the point.\n",
    "with respect to the mesh centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba17ee-f59e-4804-95f8-b86f5ee3c49f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nerf_grasping.sim import acronym_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4caff0-c4d7-4fc8-ab24-2100638b6432",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from localscope import localscope\n",
    "import time\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "import trimesh\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as mplot3d\n",
    "\n",
    "from nerf_grasping.grasp_utils import nerf_to_ig, ig_to_nerf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7fd81e-386e-422a-9259-73944fd2a27e",
   "metadata": {},
   "source": [
    "# Read in Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1583783f-3583-4861-84e3-c0317c94b265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj_class_names = [\n",
    "    k for k in tqdm(list(acronym_objects.__dict__.keys())) if k.startswith(\"Obj_\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594a46d-813a-4548-8b24-4702d3783102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nerf_checkpoints_path = \"nerf_checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195cbba-3c70-48e5-b5a4-6c0d61999858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoints = os.listdir(nerf_checkpoints_path)\n",
    "checkpoints_set = set(checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11520f50-8554-4867-82d0-7411e6fab736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get objs with checkpoint, hacky\n",
    "objs = []\n",
    "for obj_class_name in tqdm(obj_class_names):\n",
    "    workspace = \"isaac_\" + eval(f\"acronym_objects.{obj_class_name}.workspace\")\n",
    "    if workspace in checkpoints_set:\n",
    "        objs.append(eval(f\"acronym_objects.{obj_class_name}()\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61556e2b-acdb-4db3-a101-029f7581c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {len(objs)} objs\")\n",
    "print(f\"First 10 are {objs[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b165e-f846-478d-9968-2df2339d7432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "found_invalid_workspace = False\n",
    "for obj in objs:\n",
    "    workspace_path = os.path.join(nerf_checkpoints_path, \"isaac_\" + obj.workspace)\n",
    "    checkpoints_path = os.path.join(workspace_path, \"checkpoints\")\n",
    "    if (\n",
    "        not os.path.exists(workspace_path)\n",
    "        or not os.path.exists(checkpoints_path)\n",
    "        or len(os.listdir(checkpoints_path)) == 0\n",
    "    ):\n",
    "        print(f\"workspace_path = {workspace_path} missing files\")\n",
    "        found_invalid_workspace = True\n",
    "if not found_invalid_workspace:\n",
    "    print(\"All workspaces are valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d010a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful constants\n",
    "LEFT_TIP_POSITION_GRASP_FRAME = np.array(\n",
    "    [4.10000000e-02, -7.27595772e-12, 1.12169998e-01]\n",
    ")\n",
    "RIGHT_TIP_POSITION_GRASP_FRAME = np.array(\n",
    "    [-4.10000000e-02, -7.27595772e-12, 1.12169998e-01]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cb3d4f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "@localscope.mfc\n",
    "def position_to_transformed_positions(position, transforms):\n",
    "    assert position.shape == (3,)\n",
    "    assert len(transforms.shape) == 3 and transforms.shape[1:] == (4, 4)\n",
    "    num_transforms = transforms.shape[0]\n",
    "\n",
    "    # transformed_positions = (transforms @ np.array([*position, 1.0]).reshape(1, 4, 1))[\n",
    "    #     :, :3, :\n",
    "    # ].squeeze()\n",
    "    transformed_positions = (transforms @ np.array([*position, 1.0]).reshape(1, 4, 1))[\n",
    "        :, :3, :\n",
    "    ].squeeze(-1)\n",
    "    assert transformed_positions.shape == (num_transforms, 3)\n",
    "    return transformed_positions\n",
    "\n",
    "\n",
    "@localscope.mfc\n",
    "def position_to_transformed_positions_unvectorized(position, transforms):\n",
    "    assert position.shape == (3,)\n",
    "    assert len(transforms.shape) == 3 and transforms.shape[1:] == (4, 4)\n",
    "    num_transforms = transforms.shape[0]\n",
    "\n",
    "    transformed_positions = []\n",
    "    for i in range(num_transforms):\n",
    "        transformed_positions.append((transforms[i] @ np.array([*position, 1.0]))[:3])\n",
    "    transformed_positions = np.stack(transformed_positions)\n",
    "    return transformed_positions\n",
    "\n",
    "\n",
    "@localscope.mfc\n",
    "def run_sanity_check(position, transforms):\n",
    "    # Non-vectorized\n",
    "    start = time.time()\n",
    "    positions_object_frame = position_to_transformed_positions_unvectorized(\n",
    "        position=position, transforms=transforms\n",
    "    )\n",
    "    print(f\"Non-vectorized took {1000 * (time.time() - start):.2f} ms\")\n",
    "\n",
    "    # Vectorized version\n",
    "    start = time.time()\n",
    "    positions_object_frame_2 = position_to_transformed_positions(\n",
    "        position=position, transforms=transforms\n",
    "    )\n",
    "    print(f\"Vectorized took {1000 * (time.time() - start):.2f} ms\")\n",
    "\n",
    "    assert np.max(np.abs(positions_object_frame - positions_object_frame_2)) < 1e-5\n",
    "    print(\"Passed the test, they match!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c6ab90-2aff-4846-ba67-13f6bc9f3a63",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run_sanity_check(position=LEFT_TIP_POSITION_GRASP_FRAME, transforms=grasp_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc09d9c-b41c-44e0-8b70-f89bd4be7bdb",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "@localscope.mfc\n",
    "def plot_obj(obj_filepath, scale=1.0, offset=None, color=\"lightpink\"):\n",
    "    if offset is None:\n",
    "        offset = np.zeros(3)\n",
    "\n",
    "    # Read in the OBJ file\n",
    "    with open(obj_filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Extract the vertex coordinates and faces from the OBJ file\n",
    "    vertices = []\n",
    "    faces = []\n",
    "    for line in lines:\n",
    "        if line.startswith(\"v \"):\n",
    "            vertex = [float(i) * scale for i in line.split()[1:4]]\n",
    "            vertices.append(vertex)\n",
    "        elif line.startswith(\"f \"):\n",
    "            face = [int(i.split(\"/\")[0]) - 1 for i in line.split()[1:4]]\n",
    "            faces.append(face)\n",
    "\n",
    "    # Convert the vertex coordinates and faces to numpy arrays\n",
    "    vertices = np.array(vertices)\n",
    "    faces = np.array(faces)\n",
    "\n",
    "    assert len(vertices.shape) == 2 and vertices.shape[1] == 3\n",
    "    assert len(faces.shape) == 2 and faces.shape[1] == 3\n",
    "\n",
    "    vertices += offset.reshape(1, 3)\n",
    "\n",
    "    # Create the mesh3d trace\n",
    "    mesh = go.Mesh3d(\n",
    "        x=vertices[:, 0],\n",
    "        y=vertices[:, 1],\n",
    "        z=vertices[:, 2],\n",
    "        i=faces[:, 0],\n",
    "        j=faces[:, 1],\n",
    "        k=faces[:, 2],\n",
    "        color=color,\n",
    "        opacity=0.5,\n",
    "        name=f\"Mesh: {os.path.basename(obj_filepath)}\",\n",
    "    )\n",
    "\n",
    "    # Create the layout\n",
    "    coordinates = \"Object Coordinates\" if np.all(offset == 0) else \"Isaac Coordinates\"\n",
    "    layout = go.Layout(\n",
    "        scene=dict(xaxis=dict(title=\"X\"), yaxis=dict(title=\"Y\"), zaxis=dict(title=\"Z\")),\n",
    "        showlegend=True,\n",
    "        title=f\"Mesh: {os.path.basename(obj_filepath)} ({coordinates})\",\n",
    "        width=800,\n",
    "        height=800,\n",
    "    )\n",
    "\n",
    "    # Create the figure\n",
    "    fig = go.Figure(data=[mesh], layout=layout)\n",
    "\n",
    "    # Return the figure\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313b9f1-cc77-4110-b80b-f7d081cf463b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@localscope.mfc\n",
    "def get_mesh_centroid(mesh, scale=1):\n",
    "    return np.array(mesh.centroid) * scale\n",
    "\n",
    "\n",
    "# Get bounds of mesh\n",
    "@localscope.mfc\n",
    "def get_mesh_bounds(mesh, scale=1):\n",
    "    min_points, max_points = mesh.bounds\n",
    "    return np.array(min_points) * scale, np.array(max_points) * scale\n",
    "\n",
    "\n",
    "@localscope.mfc\n",
    "def get_mesh_centroid_scatter(mesh_centroid, offset=None):\n",
    "    if offset is None:\n",
    "        offset = np.zeros(3)\n",
    "\n",
    "    translated_mesh_centroid = mesh_centroid + offset\n",
    "    scatter = go.Scatter3d(\n",
    "        x=[translated_mesh_centroid[0]],\n",
    "        y=[translated_mesh_centroid[1]],\n",
    "        z=[translated_mesh_centroid[2]],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=10, color=\"black\"),\n",
    "        name=\"Mesh Centroid\",\n",
    "    )\n",
    "    return scatter\n",
    "\n",
    "\n",
    "@localscope.mfc\n",
    "def get_mesh_origin_lines(offset=None):\n",
    "    if offset is None:\n",
    "        offset = np.zeros(3)\n",
    "\n",
    "    x_line_np = np.array([[0.0, 0.0, 0.0], [0.1, 0.0, 0.0]])\n",
    "    y_line_np = np.array([[0.0, 0.0, 0.0], [0.0, 0.1, 0.0]])\n",
    "    z_line_np = np.array([[0.0, 0.0, 0.0], [0.0, 0.0, 0.1]])\n",
    "\n",
    "    lines = []\n",
    "    for line_np, name, color in [\n",
    "        (x_line_np, \"X\", \"red\"),\n",
    "        (y_line_np, \"Y\", \"green\"),\n",
    "        (z_line_np, \"Z\", \"blue\"),\n",
    "    ]:\n",
    "        line_np += offset\n",
    "        lines.append(\n",
    "            go.Scatter3d(\n",
    "                x=line_np[:, 0],\n",
    "                y=line_np[:, 1],\n",
    "                z=line_np[:, 2],\n",
    "                mode=\"lines\",\n",
    "                line=dict(width=2, color=color),\n",
    "                name=f\"Mesh Origin {name} Axis\",\n",
    "            )\n",
    "        )\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144cbd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "@localscope.mfc(\n",
    "    allowed=[\n",
    "        \"LEFT_TIP_POSITION_GRASP_FRAME\",\n",
    "        \"RIGHT_TIP_POSITION_GRASP_FRAME\",\n",
    "    ]\n",
    ")\n",
    "def get_grasp_gripper_lines(grasp_transforms, grasp_successes, offset=None):\n",
    "    if offset is None:\n",
    "        offset = np.zeros(3)\n",
    "\n",
    "    raw_left_tip = LEFT_TIP_POSITION_GRASP_FRAME\n",
    "    raw_right_tip = RIGHT_TIP_POSITION_GRASP_FRAME\n",
    "    raw_left_knuckle = LEFT_TIP_POSITION_GRASP_FRAME - np.array([0.0, 0.0, 0.04617])\n",
    "    raw_right_knuckle = RIGHT_TIP_POSITION_GRASP_FRAME - np.array([0.0, 0.0, 0.04617])\n",
    "    raw_hand_origin = np.array([0.0, 0.0, 0.0])\n",
    "    left_tips = position_to_transformed_positions(\n",
    "        position=raw_left_tip, transforms=grasp_transforms\n",
    "    )\n",
    "    right_tips = position_to_transformed_positions(\n",
    "        position=raw_right_tip, transforms=grasp_transforms\n",
    "    )\n",
    "    left_knuckles = position_to_transformed_positions(\n",
    "        position=raw_left_knuckle, transforms=grasp_transforms\n",
    "    )\n",
    "    right_knuckles = position_to_transformed_positions(\n",
    "        position=raw_right_knuckle, transforms=grasp_transforms\n",
    "    )\n",
    "    hand_origins = position_to_transformed_positions(\n",
    "        position=raw_hand_origin, transforms=grasp_transforms\n",
    "    )\n",
    "\n",
    "    assert (\n",
    "        left_tips.shape\n",
    "        == right_tips.shape\n",
    "        == left_knuckles.shape\n",
    "        == right_knuckles.shape\n",
    "        == hand_origins.shape\n",
    "        == (len(grasp_successes), 3)\n",
    "    )\n",
    "\n",
    "    grasp_lines = []\n",
    "    for i, (\n",
    "        left_tip,\n",
    "        right_tip,\n",
    "        left_knuckle,\n",
    "        right_knuckle,\n",
    "        hand_origin,\n",
    "        grasp_success,\n",
    "    ) in enumerate(\n",
    "        zip(\n",
    "            left_tips,\n",
    "            right_tips,\n",
    "            left_knuckles,\n",
    "            right_knuckles,\n",
    "            hand_origins,\n",
    "            grasp_successes,\n",
    "        )\n",
    "    ):\n",
    "        assert grasp_success in [0, 1]\n",
    "        color = \"green\" if grasp_success == 1 else \"red\"\n",
    "\n",
    "        # left tip => left knuckle => right knuckle => right tip => right_knuckle => btwn knuckles => hand_origin\n",
    "        btwn_knuckles = (left_knuckle + right_knuckle) / 2\n",
    "\n",
    "        points = np.stack(\n",
    "            [\n",
    "                left_tip,\n",
    "                left_knuckle,\n",
    "                right_knuckle,\n",
    "                right_tip,\n",
    "                btwn_knuckles,\n",
    "                hand_origin,\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        assert points.shape == (6, 3)\n",
    "\n",
    "        points += offset.reshape(1, 3)\n",
    "\n",
    "        # Create 1 continous line per grasp\n",
    "        grasp_line = go.Scatter3d(\n",
    "            x=points[:, 0],\n",
    "            y=points[:, 1],\n",
    "            z=points[:, 2],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=color, width=5),\n",
    "            name=f\"Grasp {i}\",\n",
    "        )\n",
    "        grasp_lines.append(grasp_line)\n",
    "    return grasp_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9521a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@localscope.mfc(\n",
    "    allowed=[\n",
    "        \"LEFT_TIP_POSITION_GRASP_FRAME\",\n",
    "        \"RIGHT_TIP_POSITION_GRASP_FRAME\",\n",
    "    ]\n",
    ")\n",
    "def get_grasp_ray_lines(grasp_transforms, grasp_successes, offset=None):\n",
    "    if offset is None:\n",
    "        offset = np.zeros(3)\n",
    "\n",
    "    raw_left_tip = LEFT_TIP_POSITION_GRASP_FRAME\n",
    "    raw_right_tip = RIGHT_TIP_POSITION_GRASP_FRAME\n",
    "    left_tips = position_to_transformed_positions(\n",
    "        position=raw_left_tip, transforms=grasp_transforms\n",
    "    )\n",
    "    right_tips = position_to_transformed_positions(\n",
    "        position=raw_right_tip, transforms=grasp_transforms\n",
    "    )\n",
    "\n",
    "    assert left_tips.shape == right_tips.shape == (len(grasp_successes), 3)\n",
    "    left_tips += offset.reshape(1, 3)\n",
    "    right_tips += offset.reshape(1, 3)\n",
    "\n",
    "    grasp_lines = []\n",
    "    for i, (\n",
    "        left_tip,\n",
    "        right_tip,\n",
    "        grasp_success,\n",
    "    ) in enumerate(\n",
    "        zip(\n",
    "            left_tips,\n",
    "            right_tips,\n",
    "            grasp_successes,\n",
    "        )\n",
    "    ):\n",
    "        assert grasp_success in [0, 1]\n",
    "        color = \"green\" if grasp_success == 1 else \"red\"\n",
    "\n",
    "        # left tip => right_tip\n",
    "        points = np.stack(\n",
    "            [\n",
    "                left_tip,\n",
    "                right_tip,\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        assert points.shape == (2, 3)\n",
    "\n",
    "        # Create 1 continous line per grasp\n",
    "        grasp_line = go.Scatter3d(\n",
    "            x=points[:, 0],\n",
    "            y=points[:, 1],\n",
    "            z=points[:, 2],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=color, width=5),\n",
    "            name=f\"Grasp {i}\",\n",
    "        )\n",
    "        grasp_lines.append(grasp_line)\n",
    "    return grasp_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef529909-c6f8-4e99-9da9-4e80df5a1bfc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Grid of points in grasp frame (x, y, z)\n",
    "GRIPPER_WIDTH_MM = 82\n",
    "GRIPPER_FINGER_WIDTH_MM = 20\n",
    "GRIPPER_FINGER_HEIGHT_MM = 36\n",
    "\n",
    "# Want points equally spread out in space\n",
    "DIST_BTWN_PTS_MM = 1\n",
    "\n",
    "# +1 to include both end points\n",
    "NUM_PTS_X = int(GRIPPER_WIDTH_MM / DIST_BTWN_PTS_MM) + 1\n",
    "NUM_PTS_Y = int(GRIPPER_FINGER_WIDTH_MM / DIST_BTWN_PTS_MM) + 1\n",
    "NUM_PTS_Z = int(GRIPPER_FINGER_HEIGHT_MM / DIST_BTWN_PTS_MM) + 1\n",
    "\n",
    "assert (NUM_PTS_X - 1) * DIST_BTWN_PTS_MM == GRIPPER_WIDTH_MM\n",
    "assert (NUM_PTS_Y - 1) * DIST_BTWN_PTS_MM == GRIPPER_FINGER_WIDTH_MM\n",
    "assert (NUM_PTS_Z - 1) * DIST_BTWN_PTS_MM == GRIPPER_FINGER_HEIGHT_MM\n",
    "\n",
    "\n",
    "@localscope.mfc(\n",
    "    allowed=[\n",
    "        \"LEFT_TIP_POSITION_GRASP_FRAME\",\n",
    "        \"RIGHT_TIP_POSITION_GRASP_FRAME\",\n",
    "        \"NUM_PTS_X\",\n",
    "        \"NUM_PTS_Y\",\n",
    "        \"NUM_PTS_Z\",\n",
    "        \"GRIPPER_WIDTH_MM\",\n",
    "        \"GRIPPER_FINGER_WIDTH_MM\",\n",
    "        \"GRIPPER_FINGER_HEIGHT_MM\",\n",
    "    ]\n",
    ")\n",
    "def get_grasp_query_points_grasp_frame():\n",
    "    num_pts = NUM_PTS_X * NUM_PTS_Y * NUM_PTS_Z\n",
    "    print(f\"num_pts: {num_pts}\")\n",
    "\n",
    "    GRIPPER_WIDTH_M = GRIPPER_WIDTH_MM / 1000.0\n",
    "    GRIPPER_FINGER_WIDTH_M = GRIPPER_FINGER_WIDTH_MM / 1000.0\n",
    "    GRIPPER_FINGER_HEIGHT_M = GRIPPER_FINGER_HEIGHT_MM / 1000.0\n",
    "\n",
    "    # Create grid of points in grasp frame with shape (NUM_PTS_X, NUM_PTS_Y, NUM_PTS_Z, 3)\n",
    "    # So that grid_of_points[2, 3, 5] = [x, y, z], where x, y, z are the coordinates of the point\n",
    "    x_coords = np.linspace(-GRIPPER_WIDTH_M / 2, GRIPPER_WIDTH_M / 2, NUM_PTS_X)\n",
    "    y_coords = np.linspace(\n",
    "        -GRIPPER_FINGER_WIDTH_M / 2, GRIPPER_FINGER_WIDTH_M / 2, NUM_PTS_Y\n",
    "    )\n",
    "    z_coords = np.linspace(\n",
    "        -GRIPPER_FINGER_HEIGHT_M / 2, GRIPPER_FINGER_HEIGHT_M / 2, NUM_PTS_Z\n",
    "    )\n",
    "\n",
    "    # Offset so centered between LEFT_TIP_POSITION_GRASP_FRAME and RIGHT_TIP_POSITION_GRASP_FRAME\n",
    "    center_point = (LEFT_TIP_POSITION_GRASP_FRAME + RIGHT_TIP_POSITION_GRASP_FRAME) / 2\n",
    "    x_coords += center_point[0]\n",
    "    y_coords += center_point[1]\n",
    "    z_coords += center_point[2]\n",
    "\n",
    "    xx, yy, zz = np.meshgrid(x_coords, y_coords, z_coords, indexing=\"ij\")\n",
    "    assert xx.shape == yy.shape == zz.shape == (NUM_PTS_X, NUM_PTS_Y, NUM_PTS_Z)\n",
    "    grid_of_points = np.stack([xx, yy, zz], axis=-1)\n",
    "    assert grid_of_points.shape == (NUM_PTS_X, NUM_PTS_Y, NUM_PTS_Z, 3)\n",
    "    return grid_of_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e5aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform query points to object frame\n",
    "\n",
    "\n",
    "@localscope.mfc\n",
    "def get_transformed_points(points, transform):\n",
    "    assert len(points.shape) == 2 and points.shape[1] == 3\n",
    "    assert transform.shape == (4, 4)\n",
    "\n",
    "    points_homogeneous = np.concatenate([points, np.ones((points.shape[0], 1))], axis=1)\n",
    "\n",
    "    # First (4, 4) @ (4, N) = (4, N)\n",
    "    # Then transpose to get (N, 4)\n",
    "    transformed_points = np.matmul(transform, points_homogeneous.T).T\n",
    "\n",
    "    return transformed_points[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5909bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize points\n",
    "@localscope.mfc\n",
    "def get_points_scatter(points, offset=None):\n",
    "    if offset is None:\n",
    "        offset = np.zeros(3)\n",
    "\n",
    "    assert len(points.shape) == 2 and points.shape[1] == 3\n",
    "\n",
    "    points_to_plot = points + offset.reshape(1, 3)\n",
    "\n",
    "    # Use plotly to make scatter3d plot\n",
    "    scatter = go.Scatter3d(\n",
    "        x=points_to_plot[:, 0],\n",
    "        y=points_to_plot[:, 1],\n",
    "        z=points_to_plot[:, 2],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=5, color=\"blue\"),\n",
    "        name=\"Query Points\",\n",
    "    )\n",
    "\n",
    "    return scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f47fe-8e20-48a2-ad1e-227602b3dcff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from nerf import utils\n",
    "\n",
    "\n",
    "def get_root_dir():\n",
    "    root_dir = None\n",
    "    try:\n",
    "        root_dir = Path(os.path.abspath(__file__)).parents[0]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        root_dir = Path(os.path.abspath(\".\"))\n",
    "    except:\n",
    "        pass\n",
    "    if root_dir is None:\n",
    "        raise ValueError(\"Can't get path to this file\")\n",
    "    return root_dir\n",
    "\n",
    "\n",
    "root_dir = get_root_dir()\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e82760e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@localscope.mfc(allowed=[\"root_dir\"])\n",
    "def load_nerf(workspace, bound, scale):\n",
    "    parser = utils.get_config_parser()\n",
    "    opt = parser.parse_args(\n",
    "        [\n",
    "            \"--workspace\",\n",
    "            f\"{root_dir}/nerf_checkpoints/{workspace}\",\n",
    "            \"--fp16\",\n",
    "            \"--test\",\n",
    "            \"--bound\",\n",
    "            f\"{bound}\",\n",
    "            \"--scale\",\n",
    "            f\"{scale}\",\n",
    "            \"--mode\",\n",
    "            \"blender\",\n",
    "            f\"{root_dir}/torch-ngp\",\n",
    "        ]\n",
    "    )\n",
    "    # Use options to determine proper network structure.\n",
    "    if opt.ff:\n",
    "        assert opt.fp16, \"fully-fused mode must be used with fp16 mode\"\n",
    "        from nerf.network_ff import NeRFNetwork\n",
    "    elif opt.tcnn:\n",
    "        assert opt.fp16, \"tcnn mode must be used with fp16 mode\"\n",
    "        from nerf.network_tcnn import NeRFNetwork\n",
    "    else:\n",
    "        from nerf.network import NeRFNetwork\n",
    "\n",
    "    # Create uninitialized network.\n",
    "    model = NeRFNetwork(\n",
    "        bound=opt.bound,\n",
    "        cuda_ray=opt.cuda_ray,\n",
    "    )\n",
    "\n",
    "    # Create trainer with NeRF; use its constructor to load network weights from file.\n",
    "    trainer = utils.Trainer(\n",
    "        \"ngp\",\n",
    "        vars(opt),\n",
    "        model,\n",
    "        workspace=opt.workspace,\n",
    "        criterion=None,\n",
    "        fp16=opt.fp16,\n",
    "        metrics=[None],\n",
    "        use_checkpoint=\"latest\",\n",
    "    )\n",
    "    assert len(trainer.stats[\"checkpoints\"]) != 0, \"failed to load checkpoint\"\n",
    "    return trainer.model\n",
    "\n",
    "\n",
    "@localscope.mfc\n",
    "def get_nerf_densities(nerf_model, query_points):\n",
    "    \"\"\"\n",
    "    Evaluates density of a batch of grasp points, shape [B, n_f, 3].\n",
    "    query_points is torch.Tensor in nerf frame\n",
    "    \"\"\"\n",
    "    B, n_f, _ = query_points.shape\n",
    "    query_points = query_points.reshape(1, -1, 3)\n",
    "\n",
    "    return nerf_model.density(query_points).reshape(B, n_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55c22f-3237-4373-9ec6-9f292f049a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize points\n",
    "@localscope.mfc\n",
    "def get_colored_points_scatter(points, colors, offset=None):\n",
    "    if offset is None:\n",
    "        offset = np.zeros(3)\n",
    "\n",
    "    assert len(points.shape) == 2 and points.shape[1] == 3\n",
    "\n",
    "    points_to_plot = points + offset.reshape(1, 3)\n",
    "\n",
    "    # Use plotly to make scatter3d plot\n",
    "    scatter = go.Scatter3d(\n",
    "        x=points_to_plot[:, 0],\n",
    "        y=points_to_plot[:, 1],\n",
    "        z=points_to_plot[:, 2],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=colors,\n",
    "            colorscale=\"viridis\",\n",
    "            colorbar=dict(title=\"Density Scale\"),\n",
    "        ),\n",
    "        name=\"Query Points Densities\",\n",
    "    )\n",
    "\n",
    "    return scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e716ff5-6b69-4d78-b569-b3ebe389a5af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@localscope.mfc\n",
    "def get_query_points_mesh_region(min_points, max_points, n_pts_per_dim):\n",
    "    \"\"\"\n",
    "    Returns a batch of query points in the mesh region.\n",
    "    \"\"\"\n",
    "    x = np.linspace(min_points[0], max_points[0], n_pts_per_dim)\n",
    "    y = np.linspace(min_points[1], max_points[1], n_pts_per_dim)\n",
    "    z = np.linspace(min_points[2], max_points[2], n_pts_per_dim)\n",
    "    xv, yv, zv = np.meshgrid(x, y, z)\n",
    "    return np.stack([xv, yv, zv], axis=-1).reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, name_of_timed_commands, get_current_time_fn=time.perf_counter):\n",
    "        self.name = name_of_timed_commands\n",
    "        self.get_current_time_fn = get_current_time_fn\n",
    "\n",
    "    def __enter__(self):\n",
    "        # self.start = self.get_current_time_fn()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        return\n",
    "        # print(\n",
    "        #     f\"Time elapsed for '{self.name}' is {self.get_current_time_fn() - self.start} seconds\"\n",
    "        # )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd896a0-e1b8-4937-a961-dd5a86ad8300",
   "metadata": {},
   "source": [
    "# Load Data From Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a7dc2-5c73-4d38-964e-cdf9ae274203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Same query points for each grasp in grasp frame\n",
    "grasp_query_points_grasp_frame = get_grasp_query_points_grasp_frame()\n",
    "assert grasp_query_points_grasp_frame.shape == (NUM_PTS_X, NUM_PTS_Y, NUM_PTS_Z, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb74cc8-3c23-45eb-916a-eac0f14438ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Absolute paths\n",
    "root_dir = \"/juno/u/tylerlum/github_repos/nerf_grasping\"\n",
    "assets_dir_filepath = os.path.join(root_dir, \"assets\")\n",
    "objects_dir_filepath = os.path.join(assets_dir_filepath, \"objects\")\n",
    "acronym_dir_filepath = \"/juno/u/tylerlum/github_repos/acronym/data/grasps\"\n",
    "\n",
    "CREATE_PLOTS = False\n",
    "SAVE_DATASET = True\n",
    "output_hdf5_filename = os.path.join(root_dir, \"nerf_acronym_grasp_success_dataset.h5\")\n",
    "\n",
    "ACRONYM_NUM_GRASPS_PER_OBJ = 2000\n",
    "max_num_data_points = ACRONYM_NUM_GRASPS_PER_OBJ * len(objs)  # Simple heuristic\n",
    "\n",
    "if os.path.exists(output_hdf5_filename):\n",
    "    print(f\"Found {output_hdf5_filename}, removing...\")\n",
    "    os.remove(output_hdf5_filename)\n",
    "    print(\"Done removing\")\n",
    "\n",
    "with h5py.File(output_hdf5_filename, \"w\") as hdf5_file:\n",
    "    current_idx = 0\n",
    "    nerf_grid_input_dataset = hdf5_file.create_dataset(\n",
    "        \"/nerf_grid_input\",\n",
    "        shape=(max_num_data_points, 4, NUM_PTS_X, NUM_PTS_Y, NUM_PTS_Z),\n",
    "        dtype='f')\n",
    "    grasp_success_dataset = hdf5_file.create_dataset(\n",
    "        \"nerf_grasp_data/grasp_success\",\n",
    "        shape=(max_num_data_points,),\n",
    "        dtype='i')\n",
    "    \n",
    "    # TODO REMOVE\n",
    "    objs = objs[:5]\n",
    "    for selected_obj in (pbar := tqdm(objs)):\n",
    "        pbar.set_description(f\"{selected_obj.workspace}\")\n",
    "        \n",
    "        # Prepare filenames\n",
    "        nerf_model_workspace = \"isaac_\" + selected_obj.workspace\n",
    "        acronym_data_filepath = os.path.join(\n",
    "            acronym_dir_filepath, selected_obj.acronym_file\n",
    "        )\n",
    "        urdf_filepath = os.path.join(assets_dir_filepath, selected_obj.asset_file)\n",
    "        obj_filepath = os.path.join(\n",
    "            objects_dir_filepath, selected_obj._get_mesh_path_from_urdf(urdf_filepath)\n",
    "        )\n",
    "\n",
    "        # Read acronym data\n",
    "        with Timer(\"Read acronym data file\"):\n",
    "            acronym_data = h5py.File(acronym_data_filepath, \"r\")\n",
    "\n",
    "        with Timer(\"Access acronym data\"):\n",
    "            mesh_scale = float(acronym_data[\"object/scale\"][()])\n",
    "            grasp_transforms = np.array(acronym_data[\"grasps/transforms\"])\n",
    "            grasp_successes = np.array(\n",
    "                acronym_data[\"grasps/qualities/flex/object_in_gripper\"]\n",
    "            )\n",
    "\n",
    "        assert grasp_transforms.shape == (2000, 4, 4)\n",
    "        assert grasp_successes.shape == (2000,)\n",
    "\n",
    "        # Get mesh info\n",
    "        with Timer(\"Load mesh\"):\n",
    "            mesh = trimesh.load(obj_filepath, force=\"mesh\")\n",
    "\n",
    "        with Timer(\"Get mesh info\"):\n",
    "            min_points_obj_frame, max_points_obj_frame = get_mesh_bounds(\n",
    "                mesh, scale=mesh_scale\n",
    "            )\n",
    "\n",
    "            # Use this offset for all plots so that the plot is in isaac coordinates\n",
    "            bound_min_z_obj_frame = min_points_obj_frame[2]\n",
    "            mesh_centroid_obj_frame = get_mesh_centroid(mesh, scale=mesh_scale)\n",
    "\n",
    "        # Compute offset\n",
    "        obj_offset = np.array(\n",
    "            [\n",
    "                -mesh_centroid_obj_frame[0],\n",
    "                -mesh_centroid_obj_frame[1],\n",
    "                -bound_min_z_obj_frame,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Load nerf\n",
    "        print(\"Loading NeRF...\")\n",
    "        with Timer(\"Load NeRF\"):\n",
    "            nerf_model = load_nerf(workspace=nerf_model_workspace, bound=2, scale=1)\n",
    "        print(\"Done loading NeRF\")\n",
    "\n",
    "        # Make plot for each grasp\n",
    "        num_grasps = grasp_transforms.shape[0]\n",
    "        assert num_grasps == grasp_successes.shape[0]\n",
    "\n",
    "        for grasp_idx in tqdm(range(num_grasps)):\n",
    "\n",
    "            # Get grasp query points\n",
    "            with Timer(\"Get grasp query points obj frame\"):\n",
    "                grasp_query_points_object_frame = get_transformed_points(\n",
    "                    grasp_query_points_grasp_frame.reshape(-1, 3),\n",
    "                    grasp_transforms[grasp_idx],\n",
    "                )\n",
    "\n",
    "            with Timer(\"Get grasp query points nerf frame\"):\n",
    "                grasp_query_points_isaac_frame = grasp_query_points_object_frame + obj_offset.reshape(1, 3)\n",
    "                grasp_query_points_nerf_frame = ig_to_nerf(\n",
    "                    grasp_query_points_isaac_frame, return_tensor=True\n",
    "                )\n",
    "\n",
    "            with Timer(\"Get grasp query densities\"):\n",
    "                grasp_query_nerf_densities_torch = get_nerf_densities(\n",
    "                    nerf_model=nerf_model,\n",
    "                    query_points=grasp_query_points_nerf_frame.reshape(1, -1, 3)\n",
    "                    .float()\n",
    "                    .cuda(),\n",
    "                )\n",
    "\n",
    "            with Timer(\"Convert grasp query densities to numpy\"):\n",
    "                grasp_query_nerf_densities = (\n",
    "                    grasp_query_nerf_densities_torch.detach().cpu().numpy()\n",
    "                )\n",
    "            \n",
    "            with Timer(\"Reshape nerf densities\"):\n",
    "                grasp_query_nerf_densities = grasp_query_nerf_densities.reshape(NUM_PTS_X, NUM_PTS_Y, NUM_PTS_Z)\n",
    "\n",
    "            # Save dataset\n",
    "            if SAVE_DATASET:\n",
    "                mesh_centroid_isaac_frame = mesh_centroid_obj_frame + obj_offset\n",
    "                grasp_query_points_wrt_centroid = (\n",
    "                    grasp_query_points_isaac_frame\n",
    "                    - mesh_centroid_isaac_frame.reshape(1, 3)\n",
    "                )\n",
    "\n",
    "                # Merge together grasp_query_points_wrt_centroid and grasp_query_nerf_densities\n",
    "                # So goes from (83, 21, 37, 3) and (83, 21, 37) to (83, 21, 37, 4)\n",
    "                nerf_grid_input = np.concatenate(\n",
    "                    [\n",
    "                        grasp_query_points_wrt_centroid.reshape(NUM_PTS_X, NUM_PTS_Y, NUM_PTS_Z, 3),\n",
    "                        grasp_query_nerf_densities.reshape(NUM_PTS_X, NUM_PTS_Y, NUM_PTS_Z, 1),\n",
    "                    ],\n",
    "                    axis=-1,\n",
    "                )\n",
    "\n",
    "                # Switch from (83, 21, 37, 4) to (4, 83, 21, 37)\n",
    "                nerf_grid_input = np.transpose(nerf_grid_input, (3, 0, 1, 2))\n",
    "                assert nerf_grid_input.shape == (4, NUM_PTS_X, NUM_PTS_Y, NUM_PTS_Z)\n",
    "\n",
    "                nerf_grid_input_dataset[current_idx] = nerf_grid_input\n",
    "                grasp_success_dataset[current_idx] = grasp_successes[grasp_idx]\n",
    "                current_idx += 1\n",
    "\n",
    "            # Create plot of mesh\n",
    "            if CREATE_PLOTS:\n",
    "                fig = plot_obj(obj_filepath, scale=mesh_scale, offset=obj_offset)\n",
    "                mesh_centroid_scatter = get_mesh_centroid_scatter(\n",
    "                    mesh_centroid_obj_frame, offset=obj_offset\n",
    "                )\n",
    "                fig.add_trace(mesh_centroid_scatter)\n",
    "                mesh_origin_lines = get_mesh_origin_lines(offset=obj_offset)\n",
    "                for mesh_origin_line in mesh_origin_lines:\n",
    "                    fig.add_trace(mesh_origin_line)\n",
    "\n",
    "                # Plot grasps\n",
    "                USE_GRASP_RAY_LINES = True\n",
    "                if USE_GRASP_RAY_LINES:\n",
    "                    grasp_lines = get_grasp_ray_lines(\n",
    "                        grasp_transforms[grasp_idx : grasp_idx + 1],\n",
    "                        grasp_successes[grasp_idx : grasp_idx + 1],\n",
    "                        offset=obj_offset,\n",
    "                    )\n",
    "                else:\n",
    "                    grasp_lines = get_grasp_gripper_lines(\n",
    "                        grasp_transforms[grasp_idx : grasp_idx + 1],\n",
    "                        grasp_successes[grasp_idx : grasp_idx + 1],\n",
    "                        offset=obj_offset,\n",
    "                    )\n",
    "                for grasp_line in grasp_lines:\n",
    "                    fig.add_trace(grasp_line)\n",
    "\n",
    "                colored_points_scatter = get_colored_points_scatter(\n",
    "                    points=grasp_query_points_object_frame.reshape(-1, 3),\n",
    "                    colors=grasp_query_nerf_densities.reshape(-1),\n",
    "                    offset=obj_offset,\n",
    "                )\n",
    "\n",
    "                # Add the scatter plot to a figure and display it\n",
    "                fig.add_trace(colored_points_scatter)\n",
    "\n",
    "                # Avoid legend overlap\n",
    "                fig.update_layout(legend_orientation=\"h\")\n",
    "\n",
    "                PLOT_ALL_HIGH_DENSITY_POINTS = False\n",
    "                if PLOT_ALL_HIGH_DENSITY_POINTS:\n",
    "                    ## Only for fancy plot of whole nerf\n",
    "                    query_points_mesh_region_obj_frame = get_query_points_mesh_region(\n",
    "                        min_points_obj_frame, max_points_obj_frame, n_pts_per_dim=50\n",
    "                    )\n",
    "\n",
    "                    query_points_mesh_region_obj_frame.shape\n",
    "\n",
    "                    query_points_mesh_region_isaac_frame = np.copy(\n",
    "                        query_points_mesh_region_obj_frame\n",
    "                    ).reshape(-1, 3) + obj_offset.reshape(1, 3)\n",
    "                    query_points_mesh_region_nerf_frame = ig_to_nerf(\n",
    "                        query_points_mesh_region_isaac_frame.reshape(-1, 3),\n",
    "                        return_tensor=True,\n",
    "                    )\n",
    "\n",
    "                    # Compute nerf densities\n",
    "                    query_nerf_densities_torch = get_nerf_densities(\n",
    "                        nerf_model,\n",
    "                        query_points_mesh_region_nerf_frame.reshape(1, -1, 3)\n",
    "                        .float()\n",
    "                        .cuda(),\n",
    "                    ).reshape(query_points_mesh_region_nerf_frame.shape[:-1])\n",
    "                    query_nerf_densities = query_nerf_densities_torch.detach().cpu().numpy()\n",
    "\n",
    "                    points = query_points_mesh_region_obj_frame.reshape(-1, 3)\n",
    "                    densities = query_nerf_densities.reshape(-1)\n",
    "\n",
    "                    threshold = 100\n",
    "                    filtered_points = points[densities > threshold]\n",
    "                    filtered_densities = densities[densities > threshold]\n",
    "                    colored_points_scatter = get_colored_points_scatter(\n",
    "                        points=filtered_points, colors=filtered_densities, offset=obj_offset\n",
    "                    )\n",
    "\n",
    "                    # Add the scatter plot to a figure and display it\n",
    "                    fig.add_trace(colored_points_scatter)\n",
    "                    fig.update_layout(legend_orientation=\"h\")\n",
    "\n",
    "                fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a53641-fee1-4d15-a169-ce44aeb3f270",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023dbb5b-2005-4cb5-a036-c5c7dc74e978",
   "metadata": {},
   "source": [
    "# Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d740e882-dacf-4292-a494-c97602251802",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0fc77-59d6-4e75-a6bc-f35d5bb3d11a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce41955c-2ed5-4c08-bb72-b4cb12b925a3",
   "metadata": {},
   "source": [
    "# Run Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afcd138-6d40-4a73-96c0-3c6de957fb8b",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be684b-b06a-49c1-9cbc-fcfabdee5ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
