{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1395c899-1da5-44ca-84dc-8de289df9c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T23:56:49.341534Z",
     "iopub.status.busy": "2022-06-11T23:56:49.341218Z",
     "iopub.status.idle": "2022-06-11T23:56:49.352889Z",
     "shell.execute_reply": "2022-06-11T23:56:49.352279Z",
     "shell.execute_reply.started": "2022-06-11T23:56:49.341455Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d397b9-8794-4962-9b91-3f87c7275e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T23:56:49.353776Z",
     "iopub.status.busy": "2022-06-11T23:56:49.353620Z",
     "iopub.status.idle": "2022-06-11T23:56:52.596134Z",
     "shell.execute_reply": "2022-06-11T23:56:52.595670Z",
     "shell.execute_reply.started": "2022-06-11T23:56:49.353754Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing module 'gym_37' (/scr-ssd/ksrini/Downloads/isaacgym-3/python/isaacgym/_bindings/linux-x86_64/gym_37.so)\n",
      "Setting GYM_USD_PLUG_INFO_PATH to /scr-ssd/ksrini/Downloads/isaacgym-3/python/isaacgym/_bindings/linux-x86_64/usd/plugInfo.json\n",
      "PyTorch version 1.11.0+cu113\n",
      "Device count 1\n",
      "/scr-ssd/ksrini/Downloads/isaacgym-3/python/isaacgym/_bindings/src/gymtorch\n",
      "Using /afs/cs.stanford.edu/u/ksrini/.cache/torch_extensions/py37_cu113 as PyTorch extensions root...\n",
      "Emitting ninja build file /afs/cs.stanford.edu/u/ksrini/.cache/torch_extensions/py37_cu113/gymtorch/build.ninja...\n",
      "Building extension module gymtorch...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module gymtorch...\n",
      "WARNING: Unable to import pinocchio, skipping import\n",
      "WARNING: Unable to import pinocchio, skipping import\n",
      "WARNING: Unable to import pinocchio, skipping import\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, Any\n",
    "from isaacgym import gymapi, gymtorch\n",
    "from nerf_grasping.grasp_opt import grasp_matrix, rot_from_vec\n",
    "from nerf_grasping.control import pos_control, force_opt\n",
    "from nerf_grasping import grasp_utils\n",
    "from nerf_grasping.quaternions import Quaternion\n",
    "from nerf_grasping.sim import ig_utils\n",
    "from nerf_grasping.sim import ig_objects\n",
    "from nerf_grasping.sim import ig_viz_utils\n",
    "from nerf_grasping.sim.ig_robot import FingertipRobot\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import trimesh\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path(os.path.abspath(\"./\")).parents[0]\n",
    "asset_dir = f\"{root_dir}/assets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4eecbf-af1a-470e-a916-d06d45fda20b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-08T22:42:42.811800Z",
     "iopub.status.busy": "2022-06-08T22:42:42.811349Z",
     "iopub.status.idle": "2022-06-08T22:42:42.817168Z",
     "shell.execute_reply": "2022-06-08T22:42:42.815875Z",
     "shell.execute_reply.started": "2022-06-08T22:42:42.811742Z"
    },
    "tags": []
   },
   "source": [
    "## IG helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd91cef-f66d-411c-8056-16678aa9d3f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T23:56:52.597073Z",
     "iopub.status.busy": "2022-06-11T23:56:52.596926Z",
     "iopub.status.idle": "2022-06-11T23:56:52.626973Z",
     "shell.execute_reply": "2022-06-11T23:56:52.626503Z",
     "shell.execute_reply.started": "2022-06-11T23:56:52.597052Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_viewer():\n",
    "    viewer = gym.create_viewer(sim, gymapi.CameraProperties())\n",
    "    # position outside stage\n",
    "    cam_pos = gymapi.Vec3(0.7, 0.175, 0.6)\n",
    "    # position above banana\n",
    "    cam_pos = gymapi.Vec3(0.1, 0.02, 0.4)\n",
    "    cam_target = gymapi.Vec3(0, 0, 0.2)\n",
    "    gym.viewer_camera_look_at(viewer, env, cam_pos, cam_target)\n",
    "    return viewer\n",
    "\n",
    "\n",
    "def step_gym():\n",
    "    gym.simulate(sim)\n",
    "    gym.fetch_results(sim, True)\n",
    "\n",
    "    gym.step_graphics(sim)\n",
    "    if viewer is not None:\n",
    "        gym.draw_viewer(viewer, sim, True)\n",
    "        gym.sync_frame_time(sim)\n",
    "    refresh_tensors()\n",
    "\n",
    "\n",
    "def setup_env():\n",
    "    plane_params = gymapi.PlaneParams()\n",
    "    plane_params.normal = gymapi.Vec3(0, 0, 1)  # z-up!\n",
    "    gym.add_ground(sim, plane_params)\n",
    "\n",
    "    spacing = 1.0\n",
    "    env_lower = gymapi.Vec3(-spacing, -spacing, 0.0)\n",
    "    env_upper = gymapi.Vec3(spacing, spacing, spacing)\n",
    "    env = gym.create_env(sim, env_lower, env_upper, 0)\n",
    "    return env\n",
    "\n",
    "\n",
    "def refresh_tensors():\n",
    "    gym.refresh_mass_matrix_tensors(sim)\n",
    "    gym.refresh_jacobian_tensors(sim)\n",
    "    gym.refresh_dof_state_tensor(sim)\n",
    "    gym.refresh_rigid_body_state_tensor(sim)\n",
    "\n",
    "\n",
    "def setup_sim():\n",
    "    args = ig_utils.parse_arguments(description=\"Trifinger test\")\n",
    "    # only tested with this one\n",
    "    assert args.physics_engine == gymapi.SIM_PHYSX\n",
    "\n",
    "    # configure sim\n",
    "    sim_params = gymapi.SimParams()\n",
    "    sim_params.dt = 1.0 / 60.0\n",
    "\n",
    "    sim_params.up_axis = gymapi.UP_AXIS_Z\n",
    "    sim_params.gravity = gymapi.Vec3(0.0, 0.0, -9.8)\n",
    "\n",
    "    sim_params.physx.solver_type = 1\n",
    "    sim_params.physx.num_position_iterations = 6\n",
    "    sim_params.physx.num_velocity_iterations = 0\n",
    "    sim_params.physx.num_threads = args.num_threads\n",
    "    sim_params.physx.use_gpu = args.use_gpu\n",
    "    # sim_params.physx.use_gpu = True\n",
    "\n",
    "    # sim_params.use_gpu_pipeline = True\n",
    "    sim_params.use_gpu_pipeline = False\n",
    "    sim = gym.create_sim(\n",
    "        args.compute_device_id,\n",
    "        args.graphics_device_id,\n",
    "        args.physics_engine,\n",
    "        sim_params,\n",
    "    )\n",
    "    assert sim is not None\n",
    "\n",
    "    # intensity = 0.01 # for nerf generation\n",
    "    # ambient = 0.21 / intensity\n",
    "    intensity = 0.5\n",
    "    ambient = 0.10 / intensity\n",
    "    intensity = gymapi.Vec3(intensity, intensity, intensity)\n",
    "    ambient = gymapi.Vec3(ambient, ambient, ambient)\n",
    "\n",
    "    gym.set_light_parameters(sim, 0, intensity, ambient, gymapi.Vec3(0.5, 1, 1))\n",
    "    gym.set_light_parameters(sim, 1, intensity, ambient, gymapi.Vec3(1, 0, 1))\n",
    "    gym.set_light_parameters(sim, 2, intensity, ambient,\n",
    "                             gymapi.Vec3(0.5, -1, 1))\n",
    "    gym.set_light_parameters(sim, 3, intensity, ambient, gymapi.Vec3(0, 0, 1))\n",
    "    return sim\n",
    "\n",
    "\n",
    "def setup_stage(env):\n",
    "    # this one is convex decomposed\n",
    "    stage_urdf_file = \"trifinger/robot_properties_fingers/urdf/high_table_boundary.urdf\"\n",
    "    # stage_urdf_file = \"trifinger/robot_properties_fingers/urdf/trifinger_stage.urdf\"\n",
    "    # stage_urdf_file = \"trifinger/robot_properties_fingers/urdf/stage.urdf\"\n",
    "\n",
    "    asset_options = gymapi.AssetOptions()\n",
    "    asset_options.disable_gravity = True\n",
    "    asset_options.fix_base_link = True\n",
    "    asset_options.flip_visual_attachments = False\n",
    "    asset_options.use_mesh_materials = True\n",
    "    asset_options.thickness = 0.001\n",
    "\n",
    "    stage_asset = gym.load_asset(sim, asset_dir, stage_urdf_file, asset_options)\n",
    "    gym.create_actor(env,\n",
    "                     stage_asset,\n",
    "                     gymapi.Transform(),\n",
    "                     \"Stage\",\n",
    "                     0,\n",
    "                     0,\n",
    "                     segmentationId=1)\n",
    "\n",
    "\n",
    "def get_mesh_contacts(gt_mesh,\n",
    "                      grasp_points,\n",
    "                      pos_offset=None,\n",
    "                      rot_offset=None,\n",
    "                      return_dist=False):\n",
    "    if pos_offset is not None:\n",
    "        # project grasp_points into object frame\n",
    "        grasp_points -= pos_offset\n",
    "        grasp_points = np.stack([rot_offset.rotate(gp) for gp in grasp_points])\n",
    "    points, distance, index = trimesh.proximity.closest_point(\n",
    "        gt_mesh, grasp_points)\n",
    "    # grasp normals follow convention that points into surface,\n",
    "    # trimesh computes normals pointing out of surface\n",
    "    grasp_normals = -gt_mesh.face_normals[index]\n",
    "    if pos_offset is not None:\n",
    "        # project back into world frame\n",
    "        points += pos_offset\n",
    "        grasp_normals = np.stack(\n",
    "            [rot_offset.T.rotate(x) for x in grasp_normals])\n",
    "    retval = ((points, grasp_normals) if not return_dist else\n",
    "              (points, grasp_normals, distance))\n",
    "    return retval\n",
    "\n",
    "\n",
    "def random_forces(timestep):\n",
    "    fx = -np.sin(timestep * np.pi / 10) * 0.025 + 0.001\n",
    "    fy = -np.sin(timestep * np.pi / 5) * 0.025 + 0.001\n",
    "    f = np.array([[fx, fy, 0.0]] * 3)\n",
    "    return f\n",
    "\n",
    "\n",
    "def closest_point(a, b, p):\n",
    "    ap = p - a\n",
    "    ab = b - a\n",
    "    res = []\n",
    "    for i in range(3):\n",
    "        result = a[i] + torch.dot(ap[i], ab[i]) / torch.dot(ab[i],\n",
    "                                                            ab[i]) * ab[i]\n",
    "        res.append(result)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca9f9ab-41fe-4383-a245-575791bf9f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:37:50.304157Z",
     "iopub.status.busy": "2022-06-10T07:37:50.303696Z",
     "iopub.status.idle": "2022-06-10T07:37:50.332647Z",
     "shell.execute_reply": "2022-06-10T07:37:50.331927Z",
     "shell.execute_reply.started": "2022-06-10T07:37:50.304098Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Michal's FOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c57890b1-af57-42b3-8f2b-f97c54a3fb84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T23:56:52.627795Z",
     "iopub.status.busy": "2022-06-11T23:56:52.627602Z",
     "iopub.status.idle": "2022-06-11T23:56:52.781714Z",
     "shell.execute_reply": "2022-06-11T23:56:52.780592Z",
     "shell.execute_reply.started": "2022-06-11T23:56:52.627774Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "\n",
    "\n",
    "def skew_matrix(vectors):\n",
    "    skew = np.zeros(vectors.shape[:-1] + (3, 3))\n",
    "\n",
    "    skew[..., 0, 1] = -vectors[..., 2]\n",
    "    skew[..., 1, 2] = -vectors[..., 0]\n",
    "    skew[..., 2, 0] = -vectors[..., 1]\n",
    "    skew[..., 1, 0] = vectors[..., 2]\n",
    "    skew[..., 2, 1] = vectors[..., 0]\n",
    "    skew[..., 0, 2] = vectors[..., 1]\n",
    "\n",
    "    return skew\n",
    "\n",
    "\n",
    "def example_rotation_transform(normals):\n",
    "    # hopefully no one will try grabing directly under or above\n",
    "    global_z_axis = np.array([0, 0, 1])\n",
    "\n",
    "    #  n,3, 1      3, 3                       n, 3, 1\n",
    "    local_x = skew_matrix(global_z_axis) @ normals[..., None]\n",
    "\n",
    "    #  n,3,1         n,3,3              n,3,1\n",
    "    local_y = skew_matrix(normals) @ local_x\n",
    "\n",
    "    local_x /= np.linalg.norm(local_x, keepdims=True, axis=-2)\n",
    "    local_y /= np.linalg.norm(local_y, keepdims=True, axis=-2)\n",
    "\n",
    "    rotations = np.stack([local_x, local_y, normals[..., None]], axis=-1)[...,\n",
    "                                                                          0, :]\n",
    "    return rotations\n",
    "\n",
    "\n",
    "def calculate_grip_forces(positions,\n",
    "                          normals,\n",
    "                          target_force,\n",
    "                          target_torque,\n",
    "                          target_normal=0.4,\n",
    "                          mu=0.5):\n",
    "    \"\"\"positions are relative to object CG if we want unbalanced torques\"\"\"\n",
    "\n",
    "    torch_input = type(positions) == torch.Tensor\n",
    "    if torch_input:\n",
    "        assert type(\n",
    "            normals) == torch.Tensor, \"numpy vs torch needs to be consistant\"\n",
    "        assert type(target_force\n",
    "                   ) == torch.Tensor, \"numpy vs torch needs to be consistant\"\n",
    "        assert (type(target_torque) == torch.Tensor\n",
    "               ), \"numpy vs torch needs to be consistant\"\n",
    "        positions = positions.numpy()\n",
    "        normals = normals.numpy()\n",
    "        target_force = target_force.numpy()\n",
    "        target_torque = target_torque.numpy()\n",
    "\n",
    "    n, _ = positions.shape\n",
    "    assert normals.shape == (n, 3)\n",
    "    assert target_force.shape == (3,)\n",
    "\n",
    "    F = cp.Variable((n, 3))\n",
    "    constraints = []\n",
    "\n",
    "    normals = normals / np.linalg.norm(normals, axis=-1, keepdims=True)\n",
    "\n",
    "    total_force = np.zeros((3))\n",
    "    total_torque = np.zeros((3))\n",
    "\n",
    "    Q = []\n",
    "    for pos, norm, f in zip(positions, normals, F):\n",
    "        q = example_rotation_transform(norm)\n",
    "        Q.append(q)\n",
    "\n",
    "        total_force += q @ f\n",
    "        total_torque += skew_matrix(pos) @ q @ f\n",
    "\n",
    "    constraints.append(total_force == target_force)\n",
    "    constraints.append(total_torque == target_torque)\n",
    "\n",
    "    friction_cone = cp.norm(F[:, :2], axis=1) <= mu * F[:, 2]\n",
    "    constraints.append(friction_cone)\n",
    "\n",
    "    force_magnitudes = cp.norm(F - np.array([[0.0, 0.0, target_normal]]),\n",
    "                               axis=1)\n",
    "    # friction_magnitudes = cp.norm(F[:,2], axis=1)\n",
    "    prob = cp.Problem(cp.Minimize(cp.max(force_magnitudes)), constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    if F.value is None:\n",
    "        print(\"Failed to solve!\")\n",
    "        return torch.zeros(9)\n",
    "\n",
    "    global_forces = np.zeros_like(F.value)\n",
    "    for i in range(n):\n",
    "        global_forces[i, :] = Q[i] @ F.value[i, :]\n",
    "\n",
    "    if torch_input:\n",
    "        global_forces = torch.tensor(global_forces).float()\n",
    "\n",
    "    return global_forces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c75d907-2e0e-4578-a7ce-4c906ae87d87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T01:36:25.034099Z",
     "iopub.status.busy": "2022-06-10T01:36:25.033917Z"
    },
    "tags": []
   },
   "source": [
    "**Visualizing ideal + actual grasp normals and closest point**\n",
    "```python\n",
    "gt_points, gt_normals, dist = get_mesh_contacts(obj.gt_mesh, robot.position, return_dist=True)\n",
    "closest_points = closest_point(grasp_points, grasp_points + grasp_normals, robot.position)\n",
    "\n",
    "robot.reset_actor()\n",
    "obj.reset_actor()\n",
    "ig_viz_utils.visualize_grasp_normals(gym, viewer, env, robot.position, \n",
    "                                     grasp_normals, des_z_dist=dist, \n",
    "                                     colors=[[0.,1.,0.]]*3)\n",
    "ig_viz_utils.visualize_grasp_normals(gym, viewer, env, robot.position, \n",
    "                                     gt_normals.astype('float32'), des_z_dist=dist,\n",
    "                                     colors=[[1.,0.,0.]]*3)\n",
    "ig_viz_utils.visualize_markers(gym, env, sim, points)\n",
    "\n",
    "while True: step_gym()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76edff1e-18df-444e-b603-2b9d69fdc7da",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-09T06:44:40.719346Z",
     "iopub.status.idle": "2022-06-09T06:44:40.719544Z",
     "shell.execute_reply": "2022-06-09T06:44:40.719446Z"
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "gym.get_actor_dof_count(env, 3)\n",
    "\n",
    "for i in range(4):\n",
    "    print(gym.get_actor_name(env, i))\n",
    "    print(gym.get_sim_rigid_body_states(sim, gymapi.STATE_POS)[i][\"pose\"][\"p\"])\n",
    "\n",
    "Obj = ig_objects.Banana\n",
    "obj = Obj(gym, sim, env)\n",
    "robot.setup_tensors()\n",
    "obj.setup_tensors()\n",
    "\n",
    "gym.get_actor_actuator_count(env, 4)\n",
    "\n",
    "robot.setup_tensors()\n",
    "\n",
    "for i in range(5):\n",
    "    print(gym.get_actor_name(env, i))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7d870-04b0-455f-b1af-1827ec83baf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Force Opt with CvxpyLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ff845d-d7f5-44ae-85eb-3a641b9c16ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T23:56:52.783448Z",
     "iopub.status.busy": "2022-06-11T23:56:52.783131Z",
     "iopub.status.idle": "2022-06-11T23:56:52.836323Z",
     "shell.execute_reply": "2022-06-11T23:56:52.835610Z",
     "shell.execute_reply.started": "2022-06-11T23:56:52.783402Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "from diffcp import SolverError\n",
    "\n",
    "\n",
    "class ForceOptProblem:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        obj_mu=1.0,\n",
    "        mass=0.0166,\n",
    "        target_n=1.0,\n",
    "        cone_approx=False,\n",
    "        object_frame=False,\n",
    "    ):\n",
    "        self.obj_mu = obj_mu\n",
    "        self.mass = mass\n",
    "        self.target_n = target_n  # 1.0\n",
    "        self.cone_approx = cone_approx\n",
    "        self.object_frame = object_frame\n",
    "        self.setup_cvxpy_layer(target_n, obj_mu, mass)\n",
    "\n",
    "    def setup_cvxpy_layer(self, target_n=1.0, obj_mu=1.0, mass=None):\n",
    "        # Try solving optimization problem\n",
    "        # contact force decision variable\n",
    "        target_n_t = torch.as_tensor(np.array([0, 0, target_n] * 3),\n",
    "                                     dtype=torch.float32)\n",
    "        target_n_cp = cp.Parameter((9,),\n",
    "                                   name=\"target_n\",\n",
    "                                   value=target_n_t.data.numpy())\n",
    "        L = cp.Variable(9, name=\"l\")\n",
    "        W = cp.Parameter((6,), name=\"w_des\")\n",
    "        G = cp.Parameter((6, 9), name=\"grasp_m\")\n",
    "        cm = np.vstack((np.eye(3), np.zeros((3, 3)))) * mass\n",
    "\n",
    "        inputs = [G, W, target_n_cp]\n",
    "        outputs = [L]\n",
    "        # self.Cm = cp.Parameter((6, 3), value=cm*self.mass, name='com')\n",
    "\n",
    "        f_g = np.array([0, 0, -9.81])\n",
    "        if self.object_frame:\n",
    "            R_w_2_o = cp.Parameter((6, 6), name=\"r_w_2_o\")\n",
    "            w_ext = W + R_w_2_o @ cm @ f_g\n",
    "            inputs.append(R_w_2_o)\n",
    "        else:\n",
    "            w_ext = W + cm @ f_g\n",
    "\n",
    "        f = G @ L - w_ext  # generated contact forces must balance wrench\n",
    "\n",
    "        # Objective function - minimize force magnitudes\n",
    "        contact_force = L - target_n_cp\n",
    "        cost = cp.sum_squares(contact_force)\n",
    "\n",
    "        # Friction cone constraints; >= 0\n",
    "        constraints = []\n",
    "        cone_constraints = []\n",
    "        if self.cone_approx:\n",
    "            cone_constraints += [cp.abs(L[1::3]) <= self.obj_mu * L[::3]]\n",
    "            cone_constraints += [cp.abs(L[2::3]) <= self.obj_mu * L[::3]]\n",
    "        else:\n",
    "            cone_constraints.append(\n",
    "                cp.SOC(self.obj_mu * L[::3], (L[2::3] + L[1::3])[None]))\n",
    "        constraints.append(f == np.zeros(f.shape))\n",
    "\n",
    "        self.prob = cp.Problem(cp.Minimize(cost),\n",
    "                               cone_constraints + constraints)\n",
    "        self.policy = CvxpyLayer(self.prob, inputs, outputs)\n",
    "\n",
    "    def balance_force_test(self, des_wrench, balance_force, grasp_points,\n",
    "                           normals, obj_orientation):\n",
    "        if self.object_frame:\n",
    "            R_w_2_o = self.get_w2o_rot(obj_orientation)\n",
    "            weight = (R_w_2_o @ np.vstack(\n",
    "                [np.eye(3) * self.mass, np.zeros(\n",
    "                    (3, 3))]) @ np.array([0, 0, -self.gravity]))\n",
    "        else:\n",
    "            weight = np.vstack([np.eye(3), np.zeros(\n",
    "                (3, 3))]) @ np.array([0, 0, -self.gravity * self.mass])\n",
    "        G = grasp_matrix(grasp_points, normals)\n",
    "        w_ext = des_wrench + weight\n",
    "        f = G @ balance_force - w_ext\n",
    "        return f\n",
    "\n",
    "    def run_fop(self, des_wrench, grasp_points, normals, obj_orientation=None):\n",
    "        G_t = grasp_matrix(\n",
    "            grasp_points.unsqueeze(0).cpu(),\n",
    "            normals.unsqueeze(0).cpu())\n",
    "        des_wrench_t = torch.as_tensor(des_wrench, dtype=torch.float32)\n",
    "        target_n_t = torch.as_tensor(np.array([0, 0, self.target_n] * 3),\n",
    "                                     dtype=torch.float32)\n",
    "        inputs = [G_t, des_wrench_t, target_n_t]\n",
    "        if self.object_frame:\n",
    "            assert (obj_orientation is not None\n",
    "                   ), \"fop requires obj_orientation arg if using object frame\"\n",
    "            R_w_2_o = self.get_w2o_rot(obj_orientation)\n",
    "            R_w_2_o_t = torch.as_tensor(R_w_2_o, dtype=torch.float32)\n",
    "            inputs.append(R_w_2_o_t)\n",
    "        try:\n",
    "            (balance_force,) = self.policy(*inputs)\n",
    "            return balance_force\n",
    "        except SolverError:\n",
    "            return torch.zeros((3, 3), dtype=torch.float32)\n",
    "\n",
    "    def __call__(self, des_wrench, grasp_points, normals, obj_orientation=None):\n",
    "        return self.run_fop(des_wrench, grasp_points, normals, obj_orientation)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_w2o_rot(obj_orientation):\n",
    "        R_w_2_o = Rotation.from_quat(obj_orientation).as_matrix().T\n",
    "        R_w_2_o = block_diag(R_w_2_o, R_w_2_o)\n",
    "        return R_w_2_o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac02c57-17fb-4c25-9173-fd06a20372f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Object Position Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c167b04-eb39-4c6c-b193-4952128aba79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T23:57:04.566334Z",
     "iopub.status.busy": "2022-06-11T23:57:04.565860Z",
     "iopub.status.idle": "2022-06-11T23:57:04.599485Z",
     "shell.execute_reply": "2022-06-11T23:57:04.598885Z",
     "shell.execute_reply.started": "2022-06-11T23:57:04.566270Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def object_pos_control(\n",
    "    obj,\n",
    "    in_normal,\n",
    "    target_position=None,\n",
    "    target_normal=0.4,\n",
    "    kp=0.4,\n",
    "    kd=0.1,\n",
    "    return_wrench=False,\n",
    "):\n",
    "    \"\"\"Object position control for lifting trajectory\"\"\"\n",
    "    if target_position is None:\n",
    "        target_position = np.array([0.0, 0.0, robot.target_height])\n",
    "    tip_position = robot.position\n",
    "    vel = obj.velocity\n",
    "    angular_vel = obj.angular_velocity\n",
    "    quat = Quaternion.fromWLast(obj.orientation)\n",
    "    target_quat = Quaternion.Identity()\n",
    "    cg_pos = obj.get_CG()  # thoughts it eliminates the pendulum effect? possibly?\n",
    "\n",
    "    pos_error = cg_pos - target_position\n",
    "    object_weight_comp = obj.mass * 9.8 * torch.tensor([0, 0, 1])\n",
    "    # target_force = object_weight_comp - 0.9 * pos_error - 0.4 * vel\n",
    "    # banana tuning\n",
    "    target_force = object_weight_comp - kp * pos_error - kd * vel\n",
    "    target_torque = (-0.04 * (quat @ target_quat.T).to_tangent_space() -\n",
    "                     0.0001 * angular_vel)\n",
    "    if return_wrench:\n",
    "        return torch.cat([target_force, target_torque])\n",
    "    # grasp points in object frame\n",
    "    # TODO: compute tip radius here?\n",
    "    grasp_points = tip_position - cg_pos\n",
    "    in_normal = torch.stack([quat.rotate(x) for x in in_normal], axis=0)\n",
    "    try:\n",
    "        global_forces = calculate_grip_forces(\n",
    "            grasp_points,\n",
    "            in_normal,\n",
    "            target_force,\n",
    "            target_torque,\n",
    "            target_normal,\n",
    "            obj.mu,\n",
    "        )\n",
    "    except AssertionError:\n",
    "        logging.warning(\"solve failed, maintaining previous forces\")\n",
    "        global_forces = (robot.previous_global_forces\n",
    "                        )  # will fail if we failed solve on first iteration\n",
    "        assert global_forces is not None\n",
    "    else:\n",
    "        robot.previous_global_forces = global_forces\n",
    "\n",
    "    return global_forces, target_force, target_torque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1784efea-564c-4a8b-9b91-b750c22abee9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-09T06:44:40.724062Z",
     "iopub.status.idle": "2022-06-09T06:44:40.724258Z",
     "shell.execute_reply": "2022-06-09T06:44:40.724160Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load env and object\n",
    "```python\n",
    "Obj = ig_objects.Banana\n",
    "grasp_points = torch.tensor(\n",
    "    [[0.0, 0.05, 0.05], [0.03, -0.05, 0.05], [-0.03, -0.05, 0.05]]\n",
    ")\n",
    "grasp_normals = torch.tensor([[0.0, -1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0]])\n",
    "robot_kwargs = dict(grasp_vars=(grasp_points, grasp_normals))\n",
    "\n",
    "tf = TriFingertipEnv(viewer=True, robot=True, Obj=Obj, **robot_kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4da17-d37a-4513-b7ba-1dd96f58abd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b941fc-ca6d-4ff0-a662-bfb2c47ab4fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T23:57:05.966861Z",
     "iopub.status.busy": "2022-06-11T23:57:05.966411Z",
     "iopub.status.idle": "2022-06-11T23:57:10.964513Z",
     "shell.execute_reply": "2022-06-11T23:57:10.963991Z",
     "shell.execute_reply.started": "2022-06-11T23:57:05.966799Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> Trainer: ngp | <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-11_16-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">57</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span> | cu<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">da:0</span> | fp32 | \n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/scr-ssd/ksrini/nerf_grasping/torch-ngp/logs/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">banana</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m Trainer: ngp | \u001b[1;36m2022\u001b[0m-\u001b[1;36m06\u001b[0m-11_16-\u001b[1;36m57\u001b[0m-\u001b[1;36m08\u001b[0m | cu\u001b[1;92mda:0\u001b[0m | fp32 | \n",
       "\u001b[35m/scr-ssd/ksrini/nerf_grasping/torch-ngp/logs/\u001b[0m\u001b[95mbanana\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> #parameters: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12667002</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m #parameters: \u001b[1;36m12667002\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> Loading latest checkpoint <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m Loading latest checkpoint \u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> Latest checkpoint is \n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/scr-ssd/ksrini/nerf_grasping/torch-ngp/logs/banana/checkpoints/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">ngp_ep0200.pth.tar</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m Latest checkpoint is \n",
       "\u001b[35m/scr-ssd/ksrini/nerf_grasping/torch-ngp/logs/banana/checkpoints/\u001b[0m\u001b[95mngp_ep0200.pth.tar\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> loaded model.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m loaded model.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>WARN<span style=\"font-weight: bold\">]</span> unexpected keys: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'density_grid'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'step_counter'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mWARN\u001b[1m]\u001b[0m unexpected keys: \u001b[1m[\u001b[0m\u001b[32m'density_grid'\u001b[0m, \u001b[32m'step_counter'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>WARN<span style=\"font-weight: bold\">]</span> Failed to load optimizer, use default.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mWARN\u001b[1m]\u001b[0m Failed to load optimizer, use default.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>WARN<span style=\"font-weight: bold\">]</span> Failed to load scheduler, use default.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mWARN\u001b[1m]\u001b[0m Failed to load scheduler, use default.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> loaded scaler.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m loaded scaler.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gym = gymapi.acquire_gym()\n",
    "\n",
    "sim = setup_sim()\n",
    "env = setup_env()\n",
    "setup_stage(env)\n",
    "viewer = setup_viewer()\n",
    "\n",
    "Obj = ig_objects.Banana\n",
    "grasp_points, grasp_normals = Obj.grasp_points, Obj.grasp_normals\n",
    "\n",
    "grasp_normals = grasp_normals / grasp_normals.norm(dim=1, keepdim=True)\n",
    "grasp_vars = (grasp_points, grasp_normals)\n",
    "\n",
    "# Creates the robot, fop objective, and object\n",
    "robot = FingertipRobot(gym, sim, env, grasp_vars=grasp_vars)\n",
    "obj = Obj(gym, sim, env)\n",
    "fop_obj = ForceOptProblem(mass=obj.mass, target_n=0.3)\n",
    "\n",
    "robot.setup_tensors()\n",
    "obj.setup_tensors()\n",
    "obj.load_nerf_model()\n",
    "obj.load_trimesh()\n",
    "for i in range(4):\n",
    "    step_gym()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d7ddd-3c17-4041-aa5e-c1b2a9015e41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T12:22:58.544214Z",
     "iopub.status.busy": "2022-06-10T12:22:58.543765Z",
     "iopub.status.idle": "2022-06-10T12:22:58.595695Z",
     "shell.execute_reply": "2022-06-10T12:22:58.594996Z",
     "shell.execute_reply.started": "2022-06-10T12:22:58.544156Z"
    },
    "tags": []
   },
   "source": [
    "generates grasp matrix from sampled normals\n",
    "```python\n",
    "nerf_tip_pos = grasp_utils.ig_to_nerf(closest_points)\n",
    "_, grad_ests = grasp_utils.est_grads_vals(\n",
    "                obj.model,\n",
    "                nerf_tip_pos.reshape(1, -1, 3).cuda(),\n",
    "                sigma=5e-3,\n",
    "                num_samples=1000,\n",
    "                method=\"gaussian\",\n",
    "            )\n",
    "grad_ests = grad_ests.reshape(3, 3).float()\n",
    "grad_ests /= grad_ests.norm(dim=1, keepdim=True)\n",
    "grad_ests = grasp_utils.nerf_to_ig(grad_ests.cpu().detach().numpy())\n",
    "G = grasp_matrix(robot.position.cuda().unsqueeze(0), grad_ests.unsqueeze(0))[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9aaa600-4a21-4ab2-bbdb-e4ccc6e3b2b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T23:59:13.064525Z",
     "iopub.status.busy": "2022-06-11T23:59:13.064085Z",
     "iopub.status.idle": "2022-06-11T23:59:13.096552Z",
     "shell.execute_reply": "2022-06-11T23:59:13.095658Z",
     "shell.execute_reply.started": "2022-06-11T23:59:13.064466Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grasps = np.load(\"../grasp_data/banana.npy\")\n",
    "grasp_idx = 3\n",
    "\n",
    "grasp_points = torch.tensor(grasps[grasp_idx, :, :3], dtype=torch.float32)\n",
    "grasp_normals = torch.tensor(grasps[grasp_idx, :, 3:], dtype=torch.float32)\n",
    "grasp_vars = (grasp_points, grasp_normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2130fea4-46b3-4182-9109-77e4474e14e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T23:59:14.163643Z",
     "iopub.status.busy": "2022-06-11T23:59:14.163230Z",
     "iopub.status.idle": "2022-06-11T23:59:15.053544Z",
     "shell.execute_reply": "2022-06-11T23:59:15.052859Z",
     "shell.execute_reply.started": "2022-06-11T23:59:14.163584Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "robot.reset_actor(grasp_vars)\n",
    "obj.reset_actor()\n",
    "for i in range(4):\n",
    "    step_gym()\n",
    "robot.reset_actor(grasp_vars)\n",
    "obj.reset_actor()\n",
    "for i in range(50):\n",
    "    step_gym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5605c17-de26-4191-88a3-0cc1f55ff5d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-11T23:59:15.054842Z",
     "iopub.status.busy": "2022-06-11T23:59:15.054662Z",
     "iopub.status.idle": "2022-06-11T23:59:39.834046Z",
     "shell.execute_reply": "2022-06-11T23:59:39.833224Z",
     "shell.execute_reply.started": "2022-06-11T23:59:15.054816Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scr1/.pyenv/versions/miniconda3-latest/envs/nerf/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODE: grasp\n",
      "TIMESTEP: 100\n",
      "POSITION ERR: tensor([[-0.0005,  0.0006, -0.0043],\n",
      "        [ 0.0042, -0.0033, -0.0043],\n",
      "        [ 0.0038, -0.0019, -0.0043]])\n",
      "VELOCITY: tensor([[ 4.8380e-05, -2.8221e-05,  7.0067e-11],\n",
      "        [ 6.9128e-04, -1.2384e-04, -3.7534e-11],\n",
      "        [ 5.7359e-03, -4.3572e-03, -6.4454e-10]])\n",
      "FORCE MAG: tensor(0.0248)\n",
      "Z Force: tensor([-0.0046, -0.0077, -0.0071])\n",
      "OBJECT FORCES: (-0.00817434, 0.01907548, 0.09765722)\n",
      "MODE: lift\n",
      "TIMESTEP: 150\n",
      "POSITION ERR: tensor([[-0.0005,  0.0006, -0.0043],\n",
      "        [ 0.0042, -0.0033, -0.0043],\n",
      "        [ 0.0027, -0.0018, -0.0043]])\n",
      "VELOCITY: tensor([[ 4.2888e-05,  1.0576e-05,  2.4125e-10],\n",
      "        [ 6.2357e-05, -2.8006e-06,  4.7531e-11],\n",
      "        [ 9.5267e-03, -7.5245e-03, -1.2992e-09]])\n",
      "FORCE MAG: tensor(0.5482)\n",
      "Z Force: tensor([0.0924, 0.0632, 0.0328])\n",
      "OBJECT FORCES: (-1.8775463e-06, 0.03685447, 0.06012502)\n",
      "MODE: lift\n",
      "TIMESTEP: 200\n",
      "POSITION ERR: tensor([[-0.0025,  0.0059, -0.0042],\n",
      "        [-0.0052,  0.0038, -0.0053],\n",
      "        [-0.0033,  0.0035, -0.0061]])\n",
      "VELOCITY: tensor([[ 0.0083,  0.0181,  0.0477],\n",
      "        [ 0.0400, -0.0310,  0.0474],\n",
      "        [-0.0217, -0.0102,  0.0585]])\n",
      "FORCE MAG: tensor(0.5027)\n",
      "Z Force: tensor([ 0.1254,  0.0599, -0.0147])\n",
      "OBJECT FORCES: (0.08782887, 0.01890059, 0.25006452)\n",
      "MODE: lift\n",
      "TIMESTEP: 250\n",
      "POSITION ERR: tensor([[-0.0055,  0.0141, -0.0036],\n",
      "        [-0.0193,  0.0089, -0.0046],\n",
      "        [-0.0131,  0.0102, -0.0039]])\n",
      "VELOCITY: tensor([[-0.0082,  0.0335,  0.0420],\n",
      "        [ 0.0596, -0.0399,  0.0390],\n",
      "        [-0.0344, -0.0069,  0.0415]])\n",
      "FORCE MAG: tensor(0.3091)\n",
      "Z Force: tensor([0.0636, 0.0505, 0.0358])\n",
      "OBJECT FORCES: (0.0721466, -0.00027319, 0.15960892)\n",
      "MODE: lift\n",
      "TIMESTEP: 300\n",
      "POSITION ERR: tensor([[-0.0044,  0.0133, -0.0032],\n",
      "        [-0.0253,  0.0106, -0.0057],\n",
      "        [-0.0152,  0.0147, -0.0052]])\n",
      "VELOCITY: tensor([[-0.0141,  0.0403,  0.0176],\n",
      "        [ 0.0601, -0.0334, -0.0064],\n",
      "        [-0.0512, -0.0030, -0.0219]])\n",
      "FORCE MAG: tensor(0.5460)\n",
      "Z Force: tensor([0.0967, 0.0439, 0.0043])\n",
      "OBJECT FORCES: (0.1765769, -0.04084891, 0.2710671)\n",
      "MODE: lift\n",
      "TIMESTEP: 350\n",
      "POSITION ERR: tensor([[-0.0009,  0.0061, -0.0034],\n",
      "        [-0.0197,  0.0083, -0.0070],\n",
      "        [-0.0097,  0.0136, -0.0084]])\n",
      "VELOCITY: tensor([[-0.0094,  0.0200, -0.0279],\n",
      "        [ 0.0200, -0.0181, -0.0389],\n",
      "        [-0.0302,  0.0106, -0.0355]])\n",
      "FORCE MAG: tensor(0.6782)\n",
      "Z Force: tensor([ 0.1808,  0.0622, -0.0844])\n",
      "OBJECT FORCES: (0.1907517, -0.02896931, 0.2747671)\n",
      "MODE: lift\n",
      "TIMESTEP: 400\n",
      "POSITION ERR: tensor([[ 0.0012,  0.0004, -0.0030],\n",
      "        [-0.0102,  0.0043, -0.0063],\n",
      "        [-0.0028,  0.0087, -0.0072]])\n",
      "VELOCITY: tensor([[ 0.0142, -0.0070, -0.0721],\n",
      "        [-0.0314,  0.0057, -0.0186],\n",
      "        [ 0.0033,  0.0096,  0.0100]])\n",
      "FORCE MAG: tensor(0.5427)\n",
      "Z Force: tensor([ 0.1653,  0.0607, -0.0510])\n",
      "OBJECT FORCES: (0.11002436, 0.02936882, 0.2691031)\n",
      "MODE: lift\n",
      "TIMESTEP: 450\n",
      "POSITION ERR: tensor([[-0.0011,  0.0037, -0.0015],\n",
      "        [-0.0056,  0.0006, -0.0034],\n",
      "        [-0.0030,  0.0029, -0.0010]])\n",
      "VELOCITY: tensor([[ 0.0315, -0.0444, -0.0316],\n",
      "        [-0.0697,  0.0323,  0.0117],\n",
      "        [ 0.0418,  0.0096,  0.0250]])\n",
      "FORCE MAG: tensor(0.4950)\n",
      "Z Force: tensor([0.0188, 0.0677, 0.0897])\n",
      "OBJECT FORCES: (0.06343409, 0.04653971, 0.22095934)\n"
     ]
    }
   ],
   "source": [
    "states = []\n",
    "f_lift = None\n",
    "_net_cf = gym.acquire_net_contact_force_tensor(sim)\n",
    "net_cf = gymtorch.wrap_tensor(_net_cf)\n",
    "\n",
    "fop_obj.target_n = 0.1\n",
    "\n",
    "for timestep in range(500):\n",
    "    time.sleep(0.01)\n",
    "    step_gym()\n",
    "    # finds the closest contact points to the original grasp normal + grasp_point ray\n",
    "    closest_points = ig_utils.closest_point(grasp_points,\n",
    "                                            grasp_points + grasp_normals,\n",
    "                                            robot.position)\n",
    "    closest_points[:, 2] = obj.position[2] + 0.005\n",
    "    if timestep < 50:\n",
    "        mode = \"reach\"\n",
    "        f = robot.position_control(grasp_points)\n",
    "        pos_err = robot.position - grasp_points\n",
    "    elif timestep < 150:\n",
    "        mode = \"grasp\"\n",
    "        pos_err = closest_points - robot.position\n",
    "        pos_control = pos_err\n",
    "        f = torch.tensor(grasp_normals * 0.01) + pos_control\n",
    "    else:\n",
    "        mode = \"lift\"\n",
    "        pos_err = closest_points - robot.position\n",
    "        height_err = robot.target_height - obj.position[-1]\n",
    "\n",
    "        # f, target_force, target_torque = object_pos_control(\n",
    "        #     obj, grasp_normals, target_normal=0.15\n",
    "        gp, ge = get_mesh_contacts(obj.gt_mesh, closest_points)\n",
    "        ge = torch.tensor(ge, dtype=torch.float32)\n",
    "        f_lift, target_force, target_torque = object_pos_control(\n",
    "            obj, ge, target_normal=0.4, kp=0.5, kd=0.1)\n",
    "        # des_wrench = torch.cat(object_pos_control(obj, ge)[1:])\n",
    "        # des_wrench = torch.tensor([0, 0, 0.1, 0, 0, 0])\n",
    "        # f_lift = fop_obj(des_wrench, closest_points, ge)\n",
    "        f = f_lift  # + pos_err * 3\n",
    "\n",
    "    gym.refresh_net_contact_force_tensor(sim)\n",
    "    robot.apply_fingertip_forces(f)\n",
    "    if timestep >= 100 and timestep % 50 == 0:\n",
    "        print(\"MODE:\", mode)\n",
    "        print(\"TIMESTEP:\", timestep)\n",
    "        print(\"POSITION ERR:\", pos_err)\n",
    "        print(\"VELOCITY:\", robot.velocity)\n",
    "        print(\"FORCE MAG:\", f.norm())\n",
    "        print(\"Z Force:\", f[:, 2])\n",
    "        print(\"OBJECT FORCES:\", gym.get_rigid_contact_forces(sim)[obj.actor])\n",
    "        # print(f\"NET CONTACT FORCE:\", net_cf[obj.index,:])\n",
    "    if (robot.position[:, -1] >= 0.1).any():\n",
    "        break\n",
    "    state = dict(pos_err=pos_err,\n",
    "                 velocity=robot.velocity,\n",
    "                 force_mag=f.norm(dim=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
